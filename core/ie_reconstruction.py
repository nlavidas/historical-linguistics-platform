#!/usr/bin/env python3
"""
INDO-EUROPEAN RECONSTRUCTION ENGINE
Tools for Proto-Indo-European reconstruction and comparative linguistics

Features:
1. Sound correspondence detection
2. Cognate identification
3. PIE root reconstruction
4. Semantic shift tracking
5. Morphological reconstruction
6. Laryngeal theory support
7. Ablaut grade analysis
"""

import os
import re
import json
import sqlite3
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set, Any
from dataclasses import dataclass, field
from collections import defaultdict, Counter
from enum import Enum

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# PIE PHONOLOGY
# =============================================================================

class PIEPhoneme(Enum):
    """Proto-Indo-European phonemes"""
    # Stops
    P = 'p'
    B = 'b'
    BH = 'bÊ°'
    T = 't'
    D = 'd'
    DH = 'dÊ°'
    K = 'k'
    G = 'g'
    GH = 'gÊ°'
    KW = 'kÊ·'
    GW = 'gÊ·'
    GWH = 'gÊ·Ê°'
    # Laryngeals
    H1 = 'hâ‚'
    H2 = 'hâ‚‚'
    H3 = 'hâ‚ƒ'
    # Resonants
    M = 'm'
    N = 'n'
    R = 'r'
    L = 'l'
    Y = 'y'
    W = 'w'
    # Vowels
    E = 'e'
    O = 'o'
    E_LONG = 'Ä“'
    O_LONG = 'Å'

class AblautGrade(Enum):
    """Ablaut grades"""
    E_GRADE = 'e-grade'  # Full grade with e
    O_GRADE = 'o-grade'  # Full grade with o
    ZERO_GRADE = 'zero-grade'  # No vowel
    LENGTHENED_E = 'lengthened-e'  # Ä“
    LENGTHENED_O = 'lengthened-o'  # Å

# =============================================================================
# SOUND CORRESPONDENCES
# =============================================================================

# PIE to daughter language correspondences
SOUND_CORRESPONDENCES = {
    'grc': {  # Ancient Greek
        'p': 'Ï€',
        'b': 'Î²',
        'bÊ°': 'Ï†',
        't': 'Ï„',
        'd': 'Î´',
        'dÊ°': 'Î¸',
        'k': 'Îº',
        'g': 'Î³',
        'gÊ°': 'Ï‡',
        'kÊ·': ['Ï€', 'Ï„', 'Îº'],  # Context-dependent
        'gÊ·': ['Î²', 'Î´', 'Î³'],
        'gÊ·Ê°': ['Ï†', 'Î¸', 'Ï‡'],
        'hâ‚': '',  # Lost
        'hâ‚‚': 'Î±',  # Colors adjacent vowel
        'hâ‚ƒ': 'Î¿',  # Colors adjacent vowel
        'm': 'Î¼',
        'n': 'Î½',
        'r': 'Ï',
        'l': 'Î»',
        'y': '',  # Various reflexes
        'w': '',  # Lost in most positions
        's': ['Ïƒ', 'á¼'],  # Initial s > h (rough breathing)
        'e': 'Îµ',
        'o': 'Î¿',
        'Ä“': 'Î·',
        'Å': 'Ï‰',
    },
    'la': {  # Latin
        'p': 'p',
        'b': 'b',
        'bÊ°': ['f', 'b'],  # f initially, b medially
        't': 't',
        'd': 'd',
        'dÊ°': ['f', 'd'],
        'k': 'c',
        'g': 'g',
        'gÊ°': ['h', 'g'],
        'kÊ·': 'qu',
        'gÊ·': ['v', 'gu'],
        'gÊ·Ê°': ['f', 'gu'],
        'hâ‚': '',
        'hâ‚‚': 'a',
        'hâ‚ƒ': 'o',
        'm': 'm',
        'n': 'n',
        'r': 'r',
        'l': 'l',
        'y': 'i',
        'w': 'v',
        's': 's',
        'e': 'e',
        'o': 'o',
        'Ä“': 'Ä“',
        'Å': 'Å',
    },
    'got': {  # Gothic
        'p': 'f',  # Grimm's Law
        'b': 'p',
        'bÊ°': 'b',
        't': 'Ã¾',
        'd': 't',
        'dÊ°': 'd',
        'k': 'h',
        'g': 'k',
        'gÊ°': 'g',
        'kÊ·': 'Æ•',
        'gÊ·': 'q',
        'gÊ·Ê°': 'g',
        'm': 'm',
        'n': 'n',
        'r': 'r',
        'l': 'l',
        'y': 'j',
        'w': 'w',
        's': 's',
        'e': ['i', 'ai'],
        'o': ['u', 'au'],
    },
    'sa': {  # Sanskrit
        'p': 'p',
        'b': 'b',
        'bÊ°': 'bh',
        't': 't',
        'd': 'd',
        'dÊ°': 'dh',
        'k': ['k', 'c', 'Å›'],  # Satem
        'g': ['g', 'j'],
        'gÊ°': ['gh', 'h'],
        'kÊ·': 'k',  # Merged with plain velars
        'gÊ·': 'g',
        'gÊ·Ê°': 'gh',
        'hâ‚': '',
        'hâ‚‚': ['a', 'i'],
        'hâ‚ƒ': ['a', 'u'],
        'm': 'm',
        'n': 'n',
        'r': 'r',
        'l': ['l', 'r'],
        'y': 'y',
        'w': 'v',
        's': ['s', 'á¹£'],
        'e': 'a',  # Merged
        'o': 'a',
        'Ä“': 'Ä',
        'Å': 'Ä',
    }
}

# =============================================================================
# PIE ROOTS DATABASE
# =============================================================================

PIE_ROOTS = {
    # Motion verbs
    '*hâ‚ey-': {
        'meaning': 'to go',
        'reflexes': {
            'grc': ['Îµá¼¶Î¼Î¹', 'á¼°Î­Î½Î±Î¹'],
            'la': ['eÅ', 'Ä«re'],
            'sa': ['Ã©ti', 'Ã¡yati'],
            'got': ['iddja']
        },
        'ablaut': ['*hâ‚Ã©y-ti', '*hâ‚i-', '*hâ‚oy-']
    },
    '*gÊ·em-': {
        'meaning': 'to come, go',
        'reflexes': {
            'grc': ['Î²Î±Î¯Î½Ï‰', 'Î²á¿†Î½Î±Î¹'],
            'la': ['veniÅ', 'venÄ«re'],
            'sa': ['gÃ¡mati'],
            'got': ['qiman']
        }
    },
    '*stehâ‚‚-': {
        'meaning': 'to stand',
        'reflexes': {
            'grc': ['á¼µÏƒÏ„Î·Î¼Î¹', 'ÏƒÏ„á¿†Î½Î±Î¹'],
            'la': ['stÅ', 'stÄre', 'sistÅ'],
            'sa': ['tÃ­á¹£á¹­hati'],
            'got': ['standan']
        }
    },
    '*sed-': {
        'meaning': 'to sit',
        'reflexes': {
            'grc': ['á¼•Î¶Î¿Î¼Î±Î¹', 'á¼µÎ¶Ï‰'],
            'la': ['sedeÅ', 'sedÄ“re'],
            'sa': ['sÄ«dati', 'sÃ¡dati'],
            'got': ['sitan']
        }
    },
    
    # Perception verbs
    '*weid-': {
        'meaning': 'to see, know',
        'reflexes': {
            'grc': ['Îµá¼¶Î´Î¿Î½', 'Î¿á¼¶Î´Î±', 'á¼°Î´Îµá¿–Î½'],
            'la': ['videÅ', 'vidÄ“re'],
            'sa': ['vÃ©da', 'vidÃ¡ti'],
            'got': ['witan', 'wait']
        }
    },
    '*á¸±lew-': {
        'meaning': 'to hear',
        'reflexes': {
            'grc': ['ÎºÎ»ÏÏ‰', 'ÎºÎ»Î­Î¿Ï‚'],
            'la': ['cluÅ', 'inclutus'],
            'sa': ['Å›á¹›á¹‡Ã³ti', 'Å›rÃ¡vas'],
            'got': ['hliuma']
        }
    },
    
    # Transfer verbs
    '*dehâ‚ƒ-': {
        'meaning': 'to give',
        'reflexes': {
            'grc': ['Î´Î¯Î´Ï‰Î¼Î¹', 'Î´Î¿á¿¦Î½Î±Î¹'],
            'la': ['dÅ', 'dare', 'dÅnum'],
            'sa': ['dÃ¡dÄti', 'dÄnam'],
            'got': []
        }
    },
    '*bÊ°er-': {
        'meaning': 'to carry, bear',
        'reflexes': {
            'grc': ['Ï†Î­ÏÏ‰', 'Ï†Î­ÏÎµÎ¹Î½'],
            'la': ['ferÅ', 'ferre'],
            'sa': ['bhÃ¡rati'],
            'got': ['bairan']
        }
    },
    
    # Speech verbs
    '*wekÊ·-': {
        'meaning': 'to speak',
        'reflexes': {
            'grc': ['Îµá¼¶Ï€Î¿Î½', 'á¼”Ï€Î¿Ï‚'],
            'la': ['vÅx', 'vocÄre'],
            'sa': ['vÃ¡kti', 'vÃ¡cas'],
            'got': []
        }
    },
    
    # Basic nouns
    '*phâ‚‚tá¸—r': {
        'meaning': 'father',
        'reflexes': {
            'grc': ['Ï€Î±Ï„Î®Ï'],
            'la': ['pater'],
            'sa': ['pitÃ¡r-'],
            'got': ['fadar']
        }
    },
    '*mÃ©hâ‚‚tÄ“r': {
        'meaning': 'mother',
        'reflexes': {
            'grc': ['Î¼Î®Ï„Î·Ï'],
            'la': ['mÄter'],
            'sa': ['mÄtÃ¡r-'],
            'got': []
        }
    },
    '*bÊ°rÃ©hâ‚‚tÄ“r': {
        'meaning': 'brother',
        'reflexes': {
            'grc': ['Ï†ÏÎ¬Ï„Î·Ï', 'Ï†ÏÎ¬Ï„Ï‰Ï'],
            'la': ['frÄter'],
            'sa': ['bhrÄÌtar-'],
            'got': ['broÃ¾ar']
        }
    },
    '*swÃ©sÅr': {
        'meaning': 'sister',
        'reflexes': {
            'grc': [],
            'la': ['soror'],
            'sa': ['svÃ¡sar-'],
            'got': ['swistar']
        }
    },
    
    # Body parts
    '*hâ‚ƒekÊ·-': {
        'meaning': 'eye',
        'reflexes': {
            'grc': ['á½„Ïˆ', 'á½„Î¼Î¼Î±', 'á½„ÏƒÏƒÎµ'],
            'la': ['oculus'],
            'sa': ['Ã¡ká¹£i'],
            'got': ['augo']
        }
    },
    '*hâ‚‚ews-': {
        'meaning': 'ear',
        'reflexes': {
            'grc': ['Î¿á½–Ï‚'],
            'la': ['auris'],
            'sa': [],
            'got': ['auso']
        }
    },
    
    # Numbers
    '*sem-': {
        'meaning': 'one',
        'reflexes': {
            'grc': ['Îµá¼·Ï‚', 'Î¼Î¯Î±', 'á¼•Î½'],
            'la': ['semel', 'similis'],
            'sa': ['sÃ¡m'],
            'got': ['sums']
        }
    },
    '*dwÃ³hâ‚': {
        'meaning': 'two',
        'reflexes': {
            'grc': ['Î´ÏÎ¿'],
            'la': ['duo'],
            'sa': ['dvÄÌ'],
            'got': ['twai']
        }
    },
    '*trÃ©yes': {
        'meaning': 'three',
        'reflexes': {
            'grc': ['Ï„ÏÎµá¿–Ï‚'],
            'la': ['trÄ“s'],
            'sa': ['trÃ¡yas'],
            'got': ['Ã¾reis']
        }
    },
}

# =============================================================================
# DATA CLASSES
# =============================================================================

@dataclass
class Cognate:
    """A cognate set across languages"""
    pie_root: str
    meaning: str
    forms: Dict[str, List[str]]  # language -> forms
    confidence: float = 0.0
    notes: str = ""

@dataclass
class SoundChange:
    """A sound change rule"""
    source: str
    target: str
    environment: str  # e.g., "word-initial", "before vowel"
    language: str
    period: str = ""
    examples: List[Tuple[str, str]] = field(default_factory=list)

@dataclass
class Reconstruction:
    """A PIE reconstruction"""
    form: str
    meaning: str
    pos: str
    evidence: List[Dict]
    confidence: float
    notes: str = ""

# =============================================================================
# COGNATE FINDER
# =============================================================================

class CognateFinder:
    """Find cognates across IE languages"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.correspondences = SOUND_CORRESPONDENCES
        self.known_roots = PIE_ROOTS
    
    def find_cognates(self, lemma: str, source_lang: str) -> List[Cognate]:
        """Find cognates for a lemma"""
        cognates = []
        
        # Check known roots first
        for root, data in self.known_roots.items():
            reflexes = data.get('reflexes', {})
            if source_lang in reflexes:
                if lemma in reflexes[source_lang]:
                    # Found in known cognate set
                    cognates.append(Cognate(
                        pie_root=root,
                        meaning=data['meaning'],
                        forms=reflexes,
                        confidence=1.0,
                        notes="From PIE roots database"
                    ))
        
        # Try to find by sound correspondences
        if not cognates:
            potential = self._find_by_correspondences(lemma, source_lang)
            cognates.extend(potential)
        
        return cognates
    
    def _find_by_correspondences(self, lemma: str, source_lang: str) -> List[Cognate]:
        """Find potential cognates using sound correspondences"""
        # This would use the database to find similar forms
        # For now, return empty list
        return []
    
    def verify_cognate(self, forms: Dict[str, str]) -> Tuple[bool, float, str]:
        """Verify if forms are cognates"""
        # Check sound correspondences
        violations = []
        matches = 0
        total_checks = 0
        
        languages = list(forms.keys())
        
        for i, lang1 in enumerate(languages):
            for lang2 in languages[i+1:]:
                form1 = forms[lang1]
                form2 = forms[lang2]
                
                # Check initial consonant
                if form1 and form2:
                    c1 = form1[0] if form1 else ''
                    c2 = form2[0] if form2 else ''
                    
                    # Check if correspondence is valid
                    # (simplified check)
                    total_checks += 1
                    # Would need full correspondence checking here
        
        confidence = matches / total_checks if total_checks > 0 else 0.0
        
        return len(violations) == 0, confidence, "; ".join(violations)


# =============================================================================
# RECONSTRUCTION ENGINE
# =============================================================================

class ReconstructionEngine:
    """Reconstruct PIE forms from daughter language evidence"""
    
    def __init__(self):
        self.correspondences = SOUND_CORRESPONDENCES
    
    def reconstruct(self, cognate_set: Dict[str, str]) -> Reconstruction:
        """Reconstruct PIE form from cognates"""
        evidence = []
        
        # Analyze each form
        for lang, form in cognate_set.items():
            if lang in self.correspondences:
                analysis = self._analyze_form(form, lang)
                evidence.append({
                    'language': lang,
                    'form': form,
                    'analysis': analysis
                })
        
        # Attempt reconstruction
        pie_form = self._build_reconstruction(evidence)
        
        return Reconstruction(
            form=pie_form,
            meaning="",  # Would need semantic analysis
            pos="",
            evidence=evidence,
            confidence=self._calculate_confidence(evidence)
        )
    
    def _analyze_form(self, form: str, language: str) -> Dict:
        """Analyze a form in terms of PIE correspondences"""
        analysis = {
            'segments': [],
            'possible_pie': []
        }
        
        corr = self.correspondences.get(language, {})
        
        # Reverse mapping
        reverse_map = {}
        for pie, reflex in corr.items():
            if isinstance(reflex, list):
                for r in reflex:
                    if r not in reverse_map:
                        reverse_map[r] = []
                    reverse_map[r].append(pie)
            else:
                if reflex not in reverse_map:
                    reverse_map[reflex] = []
                reverse_map[reflex].append(pie)
        
        # Analyze each character
        for char in form:
            if char in reverse_map:
                analysis['segments'].append({
                    'char': char,
                    'pie_options': reverse_map[char]
                })
            else:
                analysis['segments'].append({
                    'char': char,
                    'pie_options': [char]  # Assume unchanged
                })
        
        return analysis
    
    def _build_reconstruction(self, evidence: List[Dict]) -> str:
        """Build PIE reconstruction from evidence"""
        if not evidence:
            return "*?"
        
        # Simple approach: use first form's analysis
        first = evidence[0]['analysis']
        
        pie_form = "*"
        for seg in first.get('segments', []):
            options = seg.get('pie_options', [])
            if options:
                pie_form += options[0]
        
        return pie_form
    
    def _calculate_confidence(self, evidence: List[Dict]) -> float:
        """Calculate confidence in reconstruction"""
        if not evidence:
            return 0.0
        
        # More languages = higher confidence
        lang_count = len(evidence)
        base_confidence = min(lang_count / 4, 1.0)  # Max at 4 languages
        
        return base_confidence


# =============================================================================
# ABLAUT ANALYZER
# =============================================================================

class AblautAnalyzer:
    """Analyze ablaut patterns"""
    
    # Ablaut patterns
    PATTERNS = {
        'e-grade': ['e'],
        'o-grade': ['o'],
        'zero-grade': [''],
        'lengthened-e': ['Ä“'],
        'lengthened-o': ['Å']
    }
    
    def analyze_root(self, root: str) -> Dict:
        """Analyze ablaut grades of a root"""
        # Extract the vowel
        vowel_match = re.search(r'[eÄ“oÅ]', root)
        
        if not vowel_match:
            return {'root': root, 'grades': {}}
        
        vowel = vowel_match.group()
        vowel_pos = vowel_match.start()
        
        grades = {}
        
        # Generate all grades
        prefix = root[:vowel_pos]
        suffix = root[vowel_pos + 1:]
        
        grades['e-grade'] = prefix + 'e' + suffix
        grades['o-grade'] = prefix + 'o' + suffix
        grades['zero-grade'] = prefix + suffix
        grades['lengthened-e'] = prefix + 'Ä“' + suffix
        grades['lengthened-o'] = prefix + 'Å' + suffix
        
        return {
            'root': root,
            'base_vowel': vowel,
            'grades': grades
        }
    
    def identify_grade(self, form: str, root: str) -> Optional[str]:
        """Identify which ablaut grade a form represents"""
        analysis = self.analyze_root(root)
        
        for grade, pattern in analysis['grades'].items():
            if pattern in form or form in pattern:
                return grade
        
        return None


# =============================================================================
# SEMANTIC SHIFT TRACKER
# =============================================================================

class SemanticShiftTracker:
    """Track semantic shifts across time and languages"""
    
    # Common semantic shift patterns
    SHIFT_PATTERNS = {
        'narrowing': 'General meaning becomes more specific',
        'broadening': 'Specific meaning becomes more general',
        'amelioration': 'Meaning becomes more positive',
        'pejoration': 'Meaning becomes more negative',
        'metaphor': 'Concrete to abstract or vice versa',
        'metonymy': 'Part for whole or associated concept',
        'synecdoche': 'Part for whole',
        'euphemism': 'Taboo avoidance',
    }
    
    def __init__(self, db_path: str):
        self.db_path = db_path
    
    def track_shifts(self, lemma: str, language: str) -> List[Dict]:
        """Track semantic shifts for a lemma"""
        shifts = []
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get meanings by period
        cursor.execute("""
            SELECT DISTINCT d.period, t.misc
            FROM tokens t
            JOIN sentences s ON t.sentence_id = s.id
            JOIN documents d ON s.document_id = d.id
            WHERE t.lemma = ?
            ORDER BY d.period
        """, (lemma,))
        
        meanings_by_period = defaultdict(set)
        for period, misc in cursor.fetchall():
            if misc and misc != '_':
                meanings_by_period[period].add(misc)
        
        conn.close()
        
        # Detect shifts between periods
        periods = sorted(meanings_by_period.keys())
        for i in range(len(periods) - 1):
            p1, p2 = periods[i], periods[i+1]
            m1 = meanings_by_period[p1]
            m2 = meanings_by_period[p2]
            
            # Check for changes
            new_meanings = m2 - m1
            lost_meanings = m1 - m2
            
            if new_meanings or lost_meanings:
                shifts.append({
                    'from_period': p1,
                    'to_period': p2,
                    'new_meanings': list(new_meanings),
                    'lost_meanings': list(lost_meanings)
                })
        
        return shifts


# =============================================================================
# MORPHOLOGICAL RECONSTRUCTION
# =============================================================================

class MorphologicalReconstructor:
    """Reconstruct PIE morphology"""
    
    # PIE nominal endings
    PIE_NOMINAL_ENDINGS = {
        'thematic': {
            'nom_sg': '-os',
            'gen_sg': '-osyo',
            'dat_sg': '-Åi',
            'acc_sg': '-om',
            'voc_sg': '-e',
            'nom_pl': '-Ås',
            'gen_pl': '-Åm',
            'dat_pl': '-oybÊ°os',
            'acc_pl': '-ons',
        },
        'athematic': {
            'nom_sg': '-s',
            'gen_sg': '-Ã©s/-Ã³s',
            'dat_sg': '-Ã©y',
            'acc_sg': '-mÌ¥',
            'voc_sg': '-âˆ…',
            'nom_pl': '-es',
            'gen_pl': '-Ã³m',
            'dat_pl': '-bÊ°yÃ³s',
            'acc_pl': '-nÌ¥s',
        }
    }
    
    # PIE verbal endings
    PIE_VERBAL_ENDINGS = {
        'primary_active': {
            '1sg': '-mi',
            '2sg': '-si',
            '3sg': '-ti',
            '1pl': '-mos',
            '2pl': '-te',
            '3pl': '-nti',
        },
        'secondary_active': {
            '1sg': '-m',
            '2sg': '-s',
            '3sg': '-t',
            '1pl': '-me',
            '2pl': '-te',
            '3pl': '-nt',
        },
        'perfect': {
            '1sg': '-hâ‚‚e',
            '2sg': '-thâ‚‚e',
            '3sg': '-e',
            '1pl': '-mÃ©',
            '2pl': '-Ã©',
            '3pl': '-á¸—r',
        }
    }
    
    def reconstruct_paradigm(self, root: str, pos: str) -> Dict:
        """Reconstruct full paradigm"""
        if pos == 'NOUN':
            return self._reconstruct_nominal(root)
        elif pos == 'VERB':
            return self._reconstruct_verbal(root)
        else:
            return {}
    
    def _reconstruct_nominal(self, root: str) -> Dict:
        """Reconstruct nominal paradigm"""
        paradigm = {'root': root, 'forms': {}}
        
        # Assume thematic for simplicity
        for case_num, ending in self.PIE_NOMINAL_ENDINGS['thematic'].items():
            paradigm['forms'][case_num] = f"*{root}{ending}"
        
        return paradigm
    
    def _reconstruct_verbal(self, root: str) -> Dict:
        """Reconstruct verbal paradigm"""
        paradigm = {'root': root, 'tenses': {}}
        
        # Present
        paradigm['tenses']['present'] = {}
        for person, ending in self.PIE_VERBAL_ENDINGS['primary_active'].items():
            paradigm['tenses']['present'][person] = f"*{root}{ending}"
        
        # Aorist
        paradigm['tenses']['aorist'] = {}
        for person, ending in self.PIE_VERBAL_ENDINGS['secondary_active'].items():
            paradigm['tenses']['aorist'][person] = f"*{root}{ending}"
        
        # Perfect
        paradigm['tenses']['perfect'] = {}
        for person, ending in self.PIE_VERBAL_ENDINGS['perfect'].items():
            # Perfect has reduplication
            paradigm['tenses']['perfect'][person] = f"*{root[0]}e-{root}{ending}"
        
        return paradigm


# =============================================================================
# IE COMPARATIVE DATABASE
# =============================================================================

class IEComparativeDB:
    """Database for IE comparative data"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """Initialize database tables"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # PIE roots table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS pie_roots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                root TEXT NOT NULL UNIQUE,
                meaning TEXT,
                pos TEXT,
                ablaut_grades TEXT,
                notes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # Cognates table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS cognates (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                root_id INTEGER,
                language TEXT NOT NULL,
                form TEXT NOT NULL,
                meaning TEXT,
                period TEXT,
                source TEXT,
                FOREIGN KEY (root_id) REFERENCES pie_roots(id)
            )
        """)
        
        # Sound changes table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS sound_changes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_phoneme TEXT NOT NULL,
                target_phoneme TEXT NOT NULL,
                language TEXT NOT NULL,
                environment TEXT,
                period TEXT,
                examples TEXT
            )
        """)
        
        # Semantic shifts table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS semantic_shifts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                lemma TEXT NOT NULL,
                language TEXT NOT NULL,
                old_meaning TEXT,
                new_meaning TEXT,
                shift_type TEXT,
                from_period TEXT,
                to_period TEXT
            )
        """)
        
        conn.commit()
        conn.close()
    
    def add_root(self, root: str, meaning: str, pos: str = None) -> int:
        """Add a PIE root"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO pie_roots (root, meaning, pos)
            VALUES (?, ?, ?)
        """, (root, meaning, pos))
        
        root_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return root_id
    
    def add_cognate(self, root_id: int, language: str, form: str,
                    meaning: str = None, period: str = None):
        """Add a cognate"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO cognates (root_id, language, form, meaning, period)
            VALUES (?, ?, ?, ?, ?)
        """, (root_id, language, form, meaning, period))
        
        conn.commit()
        conn.close()
    
    def get_cognates(self, root: str) -> List[Dict]:
        """Get all cognates for a root"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT c.* FROM cognates c
            JOIN pie_roots r ON c.root_id = r.id
            WHERE r.root = ?
        """, (root,))
        
        results = [dict(row) for row in cursor.fetchall()]
        conn.close()
        
        return results
    
    def populate_from_known_roots(self):
        """Populate database with known PIE roots"""
        for root, data in PIE_ROOTS.items():
            root_id = self.add_root(root, data['meaning'])
            
            for lang, forms in data.get('reflexes', {}).items():
                for form in forms:
                    self.add_cognate(root_id, lang, form)
        
        logger.info(f"Populated {len(PIE_ROOTS)} PIE roots")


# =============================================================================
# MAIN
# =============================================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        db_path = sys.argv[1]
    else:
        db_path = "/root/corpus_platform/data/ie_comparative.db"
    
    print("=" * 70)
    print("INDO-EUROPEAN RECONSTRUCTION ENGINE")
    print("=" * 70)
    
    # Initialize database
    ie_db = IEComparativeDB(db_path)
    ie_db.populate_from_known_roots()
    
    # Test cognate finder
    finder = CognateFinder(db_path)
    
    print("\nğŸ“š Testing cognate finder:")
    test_words = ['Ï€Î±Ï„Î®Ï', 'Ï†Î­ÏÏ‰', 'Îµá¼¶Î¼Î¹']
    for word in test_words:
        cognates = finder.find_cognates(word, 'grc')
        if cognates:
            print(f"\n  {word}:")
            for cog in cognates:
                print(f"    PIE: {cog.pie_root} '{cog.meaning}'")
                for lang, forms in cog.forms.items():
                    print(f"      {lang}: {', '.join(forms)}")
    
    # Test ablaut analyzer
    print("\nğŸ”„ Testing ablaut analyzer:")
    ablaut = AblautAnalyzer()
    
    for root in ['*bÊ°er-', '*weid-', '*stehâ‚‚-']:
        analysis = ablaut.analyze_root(root.replace('*', ''))
        print(f"\n  {root}:")
        for grade, form in analysis['grades'].items():
            print(f"    {grade}: *{form}")
    
    # Test morphological reconstruction
    print("\nğŸ“ Testing morphological reconstruction:")
    morph = MorphologicalReconstructor()
    
    paradigm = morph.reconstruct_paradigm('bÊ°er', 'VERB')
    print(f"\n  *bÊ°er- 'to carry' (present):")
    for person, form in paradigm['tenses']['present'].items():
        print(f"    {person}: {form}")
    
    print("\nâœ… IE Reconstruction Engine ready!")
